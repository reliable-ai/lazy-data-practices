diff --git a/algorithms/kamishima/kamfadm-2012ecmlpkdd/commands.py b/algorithms/kamishima/kamfadm-2012ecmlpkdd/commands.py
new file mode 100644
index 0000000..4d560d6
--- /dev/null
+++ b/algorithms/kamishima/kamfadm-2012ecmlpkdd/commands.py
@@ -0,0 +1,7 @@
+# minimal polyfill for commands in python3
+
+import subprocess
+
+def getoutput(cmd):
+    return subprocess.run(cmd, shell=True, encoding='utf-8', stdout=subprocess.PIPE).stdout
+
diff --git a/algorithms/kamishima/kamfadm-2012ecmlpkdd/fadm/lr/pr.py b/algorithms/kamishima/kamfadm-2012ecmlpkdd/fadm/lr/pr.py
index 593b6d6..2c28b9b 100755
--- a/algorithms/kamishima/kamfadm-2012ecmlpkdd/fadm/lr/pr.py
+++ b/algorithms/kamishima/kamfadm-2012ecmlpkdd/fadm/lr/pr.py
@@ -59,7 +59,7 @@ N_CLASSES = 2
 
 def sigmoid(x, w):
     """ sigmoid(w^T x)
-    To suppress the warnings at np.exp, do "np.seterr(all='ignore')
+    To suppress the warnings at np.exp, do "np.seterr(all='ignore')"
 
     Parameters
     ----------
@@ -178,7 +178,7 @@ class LRwPRPredictProbaType2Mixin(LRwPR):
 
         proba = np.empty((X.shape[0], N_CLASSES))
         proba[:, 1] = [sigmoid(X[i, :], coef[s[i], :])
-                       for i in xrange(X.shape[0])]
+                       for i in range(X.shape[0])]
         proba[:, 0] = 1.0 - proba[:, 1]
 
         return proba
@@ -235,7 +235,7 @@ class LRwPRFittingType1Mixin(LRwPR):
                                   dtype=np.float)
             coef = self.coef_.reshape(self.n_sfv_, self.n_features_)
 
-            for i in xrange(self.n_sfv_):
+            for i in range(self.n_sfv_):
                 clr = LogisticRegression(C=self.C, penalty='l2',
                                          fit_intercept=False)
                 clr.fit(X[s == i, :], y[s == i])
@@ -277,7 +277,7 @@ class LRwPRFittingType1Mixin(LRwPR):
         self.n_s_ = ns
         self.n_sfv_ = np.max(s) + 1
         self.c_s_ = np.array([np.sum(s == si).astype(np.float)
-                              for si in xrange(self.n_sfv_)])
+                              for si in range(self.n_sfv_)])
         self.n_features_ = X.shape[1]
         self.n_samples_ = X.shape[0]
 
@@ -302,7 +302,7 @@ class LRwPRObjetiveType4Mixin(LRwPR):
 
     def loss(self, coef_, X, y, s):
         """ loss function: negative log - likelihood with l2 regularizer
-        To suppress the warnings at np.log, do "np.seterr(all='ignore')
+        To suppress the warnings at np.log, do "np.seterr(all='ignore')"
 
         Parameters
         ----------
@@ -329,11 +329,11 @@ class LRwPRObjetiveType4Mixin(LRwPR):
 
         # sigma = Pr[y=0|x,s] = sigmoid(w(s)^T x)
         p = np.array([sigmoid(X[i, :], coef[s[i], :])
-                      for i in xrange(self.n_samples_)])
+                      for i in range(self.n_samples_)])
 
         # rho(s) = Pr[y=0|s] = \sum_{(xi,si)in D st si=s} sigma(xi,si) / #D[s]
         q = np.array([np.sum(p[s == si])
-                      for si in xrange(self.n_sfv_)]) / self.c_s_
+                      for si in range(self.n_sfv_)]) / self.c_s_
 
         # pi = Pr[y=0] = \sum_{(xi,si)in D} sigma(xi,si)
         r = np.sum(p) / self.n_samples_
@@ -388,15 +388,15 @@ class LRwPRObjetiveType4Mixin(LRwPR):
         # sigma = Pr[y=0|x,s] = sigmoid(w(s)^T x)
         # d_sigma(x,s) = d sigma / d w(s) = sigma (1 - sigma) x
         p = np.array([sigmoid(X[i, :], coef[s[i], :])
-                      for i in xrange(self.n_samples_)])
+                      for i in range(self.n_samples_)])
         dp = (p * (1.0 - p))[:, np.newaxis] * X
 
         # rho(s) = Pr[y=0|s] = \sum_{(xi,si)in D st si=s} sigma(xi,si) / #D[s]
         # d_rho(s) = \sum_{(xi,si)in D st si=s} d_sigma(xi,si) / #D[s]
         q = np.array([np.sum(p[s == si])
-                      for si in xrange(self.n_sfv_)]) / self.c_s_
+                      for si in range(self.n_sfv_)]) / self.c_s_
         dq = np.array([np.sum(dp[s == si, :], axis=0)
-                       for si in xrange(self.n_sfv_)]) \
+                       for si in range(self.n_sfv_)]) \
                        / self.c_s_[:, np.newaxis]
 
         # pi = Pr[y=0] = \sum_{(xi,si)in D} sigma(xi,si) / #D
@@ -406,7 +406,7 @@ class LRwPRObjetiveType4Mixin(LRwPR):
 
         # likelihood
         # l(si) = \sum_{x,y in D st s=si} (y - sigma(x, si)) x
-        for si in xrange(self.n_sfv_):
+        for si in range(self.n_sfv_):
             l[si, :] = np.sum((y - p)[s == si][:, np.newaxis] * X[s == si, :],
                               axis=0)
 
@@ -430,7 +430,7 @@ class LRwPRObjetiveType4Mixin(LRwPR):
             + f2[:, np.newaxis] * dq[s, :] \
             - np.outer(f3, dr)
         f = np.array([np.sum(f4[s == si, :], axis=0)
-                      for si in xrange(self.n_sfv_)])
+                      for si in range(self.n_sfv_)])
 
         # l2 regularizer
         reg = coef
diff --git a/algorithms/kamishima/kamfadm-2012ecmlpkdd/fadm/util/_base.py b/algorithms/kamishima/kamfadm-2012ecmlpkdd/fadm/util/_base.py
index 313ba29..5dd2adc 100755
--- a/algorithms/kamishima/kamfadm-2012ecmlpkdd/fadm/util/_base.py
+++ b/algorithms/kamishima/kamfadm-2012ecmlpkdd/fadm/util/_base.py
@@ -74,7 +74,7 @@ def fill_missing_with_mean(D, default=0.0):
         a data matrix whose missing values are filled
     """
 
-    for i in xrange(D.shape[1]):
+    for i in range(D.shape[1]):
         if np.any(np.isnan(D[:, i])):
             v = np.mean(D[np.isfinite(D[:, i]), i])
             if np.isnan(v):
diff --git a/algorithms/kamishima/kamfadm-2012ecmlpkdd/predict_lr.py b/algorithms/kamishima/kamfadm-2012ecmlpkdd/predict_lr.py
index 0d486cc..e609c77 100755
--- a/algorithms/kamishima/kamfadm-2012ecmlpkdd/predict_lr.py
+++ b/algorithms/kamishima/kamfadm-2012ecmlpkdd/predict_lr.py
@@ -135,7 +135,7 @@ def main(opt):
     # output prediction
     n = 0
     m = 0
-    for i in xrange(p.shape[0]):
+    for i in range(p.shape[0]):
         c = np.argmax(p[i, :])
         opt.outfile.write("%d %d " % (y[i], c))
         opt.outfile.write(" ".join(S[i, :].astype(str)) + " ")
@@ -173,7 +173,7 @@ def main(opt):
             opt.outfile.write("#classifier_%s=%s\n" %
                               (key, str(clr_info[key])))
 
-        for key, key_val in vars(opt).iteritems():
+        for key, key_val in vars(opt).items():
             opt.outfile.write("#%s=%s\n" % (key, str(key_val)))
 
     ### post process
@@ -228,7 +228,7 @@ if __name__ == '__main__':
                     default=sys.stdout, type=argparse.FileType('w'))
 
     # script specific options
-    ap.add_argument('-m', '--model', type=argparse.FileType('r'),
+    ap.add_argument('-m', '--model', type=argparse.FileType('rb'),
                     required=True)
     ap.set_defaults(ns=False)
     ap.add_argument("--ns", dest="ns", action="store_true")
diff --git a/algorithms/kamishima/kamfadm-2012ecmlpkdd/train_pr.py b/algorithms/kamishima/kamfadm-2012ecmlpkdd/train_pr.py
index 109352e..3fc90fc 100755
--- a/algorithms/kamishima/kamfadm-2012ecmlpkdd/train_pr.py
+++ b/algorithms/kamishima/kamfadm-2012ecmlpkdd/train_pr.py
@@ -171,7 +171,7 @@ def main(opt):
         clr = None
         best_loss = np.inf
         best_trial = 0
-        for trial in xrange(opt.ntry):
+        for trial in range(opt.ntry):
             logger.info("Trial No. " + str(trial + 1))
             tmp_clr = train(X, y, ns, opt)
             logger.info("loss = " + str(tmp_clr.f_loss_))
@@ -213,7 +213,7 @@ def main(opt):
     # write file
     pickle.dump(clr, opt.outfile)
     info = {}
-    for key, key_val in vars(opt).iteritems():
+    for key, key_val in vars(opt).items():
         info[key] = str(key_val)
     pickle.dump(info, opt.outfile)
 
@@ -262,9 +262,9 @@ if __name__ == '__main__':
     ap.add_argument('infilep', nargs='?', metavar='INFILE',
                     default=sys.stdin, type=argparse.FileType('r'))
     ap.add_argument('-o', '--out', dest='outfile',
-                    default=None, type=argparse.FileType('w'))
+                    default=None, type=argparse.FileType('wb'))
     ap.add_argument('outfilep', nargs='?', metavar='OUTFILE',
-                    default=sys.stdout, type=argparse.FileType('w'))
+                    default=sys.stdout, type=argparse.FileType('wb'))
 
     # script specific options
     ap.add_argument('-C', '--reg', dest='C', type=float, default=1.0)
